---
title: "Classification Template"
author: "Heaven Klair"
date: "5/6/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Importing the dataset

```{r, echo=TRUE}
#dataset = read.csv('Name of the file')
#dataset = dataset[3:5] Only take the necessary variables from the dataset
```

## Encoding the target feature as a factor

```{r, echo=TRUE}
dataset$DependentVariable = factor(dataset$DependentVariable, levels = c(0,1))
```

## Splitting the dataset into the Training and Test set

```{r, echo=TRUE}
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
```

## Feature Scaling

Scale the appropriate variables.
```{r, echo=TRUE}
#training_set[, 1:2] = scale(training_set[, 1:2])
#test_set[, 1:2] = scale(test_set[, 1:2])
```

## Fitting Logistic Regression to the Training Set

For Logistic Regression, we take the family as "binomial".
```{r, echo=TRUE}
# Create your own classifier here. Below is just an example.

#classifier = glm(formula = DependentVariable ~.,
#                 family = binomial,
#                 data = training_set)
```

## Predicting the Test Set Results

Specify the appropriate dependent Variable below to exclude it from predicting
```{r, echo=TRUE}
prob_pred = predict(classifier, type = 'response', newdata = test_set[-3])
prob_pred
```

```{r, echo=TRUE}
y_pred = ifelse(prob_pred > 0.5, 1, 0)
y_pred
```

## Making the Confusion Matrix

Confusion Matrix will help us calculate the number of correct and incorrect predictions.
```{r, echo=TRUE}
cm = table(test_set[,  3], y_pred)
cm
```

We focus on (1,1) and (2,2) elements in the matrix. These two elements are the number of correct predictions. The elements (1,2) and (2,1) are the incorrect predictions.


## Visualizing the Training set results

```{r, echo=TRUE}
library(ggplot2)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Name of the X-Column here', 'Name of the Y-Column here')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1,0)

ggplot(grid_set) +
  geom_tile(aes(x = (Name of the X-Axis here), y = (Name of the Y-Axis here), fill = factor(y_grid)),
            show.legend = F) +
  geom_point(data = set, aes(x = (Name of the X-Axis here), y = (Name of the Y-Axis here), color = Purchased),
             show.legend = F) +
  scale_fill_manual(values = c("tomato", "springgreen3")) +
  scale_color_manual(values = c("red3", "green4")) +
  scale_x_continuous(breaks = seq(floor(min(X1)), ceiling(max(X2)), by = 1)) +
  labs(title = "Logistic Regression (Training set)",
       ylab = "Name of the Y-Axis here Salary", xlab = "Name of the X-Axis here")
```



# Visualizing the Test set results
```{r, echo=TRUE}
library(ggplot2)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Name of the X-Axis here', 'Name of the Y-Axis here')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1,0)

ggplot(grid_set) +
  geom_tile(aes(x = Name of the X-Axis here, y = Name of the Y-Axis here, fill = factor(y_grid)),
            show.legend = F) +
  geom_point(data = set, aes(x = Name of the Y-Axis here, y = Name of the X-Axis here, color = Purchased),
             show.legend = F) +
  scale_fill_manual(values = c("tomato", "springgreen3")) +
  scale_color_manual(values = c("red3", "green4")) +
  scale_x_continuous(breaks = seq(floor(min(X1)), ceiling(max(X2)), by = 1)) +
  labs(title = "Logistic Regression (Test set)",
       ylab = "Name of the Y-Axis here", xlab = "Name of the X-Axis here")

```



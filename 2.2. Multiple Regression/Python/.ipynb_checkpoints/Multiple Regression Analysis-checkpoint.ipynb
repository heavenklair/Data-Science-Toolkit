{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('50_Startups.csv')\n",
    "X = dataset.iloc[:, :-1].values  # This selects all the columns except the last one because that is the dependent variable\n",
    "y = dataset.iloc[:, -1].values   # This selects only the columns except others because that is the dependent variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To translate the categorical variables into the numerical format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [3])], remainder = 'passthrough')   # The index here is of the column on which we want to apply the oneHotEncoder\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Mutiple Linear Regression Model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "# Model Created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dont have to worry about dummy variable trap, selecting the best feature (feature with highest P-value), the Linear Regression will take care of that  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Test set Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114664.42 105008.31]\n",
      " [ 90593.16  96479.51]\n",
      " [ 75692.84  78239.91]\n",
      " [ 70221.89  81229.06]\n",
      " [179790.26 191050.39]\n",
      " [171576.92 182901.99]\n",
      " [ 49753.59  35673.41]\n",
      " [102276.66 101004.64]\n",
      " [ 58649.38  49490.75]\n",
      " [ 98272.03  97483.56]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "np.set_printoptions(precision = 2) # this will display any numerical value with only two decimals after comma\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)), 1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match the values, we can infer that they are pretty close to each other. The data set does not necessarily have some perfect linear correlations, however, we can be assured that with this linear regression class, we were able to select right features with the right parameters to make these predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward Elimination is irrelevant is Python because Scikit-Learn Library automatically takes care of selecting the statiscally significant features when training the model to make accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: \n",
    "How do I use my multiple Linear Regression model to make a single prediction, for example, the profit of a startup with R&D Spend = 160000, Adminstration Spend = 130000, Marketing Spend = 300000 and state = California?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180892.25]\n"
     ]
    }
   ],
   "source": [
    "print(regressor.predict([[1, 0, 0, 160000, 130000, 300000]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values intoa double pair of square brackets makes the input exactly a 2D array.\n",
    "\n",
    "Note: Notice also that the \"California\" state was not input as a string in the last column but as a \"1, 0, 0\" in the first three column. That is because the predict method expects the one-hot-encoder value of the states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2:\n",
    "How do I get the final regression equation $y = b_0 + b_1 x_1 + b_2 x_2 + \\ldots$ with the final values of the coefficents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.85e+02  2.98e+02 -1.24e+01  7.74e-01 -9.44e-03  2.89e-02]\n",
      "49834.88507321703\n"
     ]
    }
   ],
   "source": [
    "print(regressor.coef_)\n",
    "print(regressor.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the equation of our multiple linear regression model is:\n",
    "$$ \\text{Profit} = -285 * \\text{Dummy State 1} + 298 * \\text{ Dummy State 2} - 12.4 * \\text{Dummy State 3} + 77.4 * \\text{R&D Spend} - 0.00944 * \\text{Administration} + 0.0289 * \\text{Marketing Spend} + 49834.88 $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
